{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dF0copX0ECwY"
   },
   "source": [
    "# Project 2: Classification\n",
    "---\n",
    "\n",
    "This notebook is supposed to be used to provide the solution to the project 2 of the module Introduction to Machine Learning 2019 @ ETHZ.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTGACEsDir8B"
   },
   "source": [
    "## Environmental Set-Up\n",
    "\n",
    "We first set the environment and load the later required packages, as well as fix the random seed globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpfh1zCwD9ie"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import sklearn as sl\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, RFECV, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skrebate import ReliefF, MultiSURFstar\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sn.set_context('notebook')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "random.seed(1234)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3nPfrvIjniL"
   },
   "source": [
    "\n",
    "---\n",
    "## Project 2\n",
    "\n",
    "The following section now solves the project 2 of the Introduction to Machine Learning course 2019.\n",
    "\n",
    "---\n",
    "\n",
    "### Formatting the data\n",
    "\n",
    "To start of we load the data from the file system into the handy pandas dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "yn_uxXJyjniC",
    "outputId": "7feabbf2-7d1e-4779-9c2e-8fe585ed3c31"
   },
   "outputs": [],
   "source": [
    "# Get train data\n",
    "train = pd.read_hdf('/path/to/train/data/h5', 'train')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MPbHzS-Pjnh_"
   },
   "source": [
    "We quickly inspect the shape of the data to make sure the data has been correctly loaded and casted into a pandas data frame. Now we also load the sample submission file (to get an idea of the format) and the test data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "RZJWfUTijniH",
    "outputId": "fdf21745-58a1-4641-c73b-a7c3dac70cc0"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get sample prediction file format.\n",
    "Sample predictions will be simply replaced with the ones obtained from the\n",
    "custom model.\n",
    "''' \n",
    "\n",
    "submission = pd.read_csv('/path/to/sample/submission/csv', index_col=0, float_precision='high')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "oa_cRBP6jnh3",
    "outputId": "01f0a79a-051a-4794-a3a6-dfbc23a2fafd"
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_hdf('/path/to/test/data/h5', 'test')\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzcpbIP5jnh1"
   },
   "source": [
    "That looks very good. We seperate the label from the features for the sake of handiness of our implementations and data handling in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Obvw7tikjnhs"
   },
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 1:]\n",
    "y_train = train.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsbJ9914k35E"
   },
   "source": [
    "---\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "Before starting with trying to model the data, we will have a first look at the data. First we will look at the distribution of the labels in the training data, since knowing if the data is balanced or not heavily influences the choice of algorithms we will consider later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "2cG63Oi_mqVj",
    "outputId": "3e5343bd-4e1a-4b49-a2fc-d303a4fa110c"
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(np.array(y_train), [-0.25, 0.25, 0.75,1.25,1.75, 2.25],\n",
    "                            facecolor='b', alpha=0.75, align=\"mid\")\n",
    "\n",
    "\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Rel. Frequency')\n",
    "plt.title('Histogram of Class Labels in the Training Data')\n",
    "plt.axis([-0.5, 3, 0, 700])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikH2x99zyYr1"
   },
   "source": [
    "We see that the number of training samples we have for each class is roughly the same and about 650. This is good since many classification algorithms are sensitive to class imbalances. We will now investigate the correlation structure between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "aXeaK65bu-7T",
    "outputId": "13b9f79f-25ab-4457-9cee-3e09e5c29308"
   },
   "outputs": [],
   "source": [
    "corr = X_train.corr()\n",
    "print(X_train.shape)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_title(\"Heatmap of the correlation structure\")\n",
    "sn.heatmap(\n",
    "    corr,\n",
    "    mask=np.zeros_like(corr, dtype=np.bool),\n",
    "    cmap=sn.diverging_palette(220, 10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "plKis-tSzKik"
   },
   "source": [
    "We see a couple strong correlations, that are e.g. between $x_9$ and $x_{19}$ or $x_{10}$ and $x_{20}$. Additionally we see that $x_{18}$ and $x_{20}$ seem to be also very strongly correlated. We see a somewhat weaker but still quite strong correlation between $x_{14}$ and $x_{15}$. All those insights suggest that feature reduction techniques might stabilize the solution, as our features are likely to be subject to multicollinearity.\n",
    "\n",
    "While the visual inspection gave us a first idea let us numerically compute the pair-wise correlations and list the 10 variable pairs that are the most correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znEFR3Rr2l3K"
   },
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "QeW-bKgo3LY-",
    "outputId": "2658529e-6dc5-4b72-c1c5-4c20f0760ebe"
   },
   "outputs": [],
   "source": [
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(X_train, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zS_DcQqD3Yeb"
   },
   "source": [
    "As indicated by our heat map we see that four pairs are correlated 1-to-1 that is one variable is a multiple of the other. Hence, we will for sure drop $x_{18}, x_{19}, x_{20}$ as those do not yield any additional information given we include $x_9$ and $x_{10}$, but are likely increase the variance of our estimators as we would have to fit weights for those. Additionally multicollinearity is known to cause unstable solutions. This we also would like to avoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITjOZcRH4DMf"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['x18','x19', 'x20'], axis=1)\n",
    "X_test = X_test.drop(['x18','x19', 'x20'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pGDa2AQJ44X1"
   },
   "source": [
    "Let us quickly validate if the issue of the 1-to-1 correlated variables is solved thereby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "IM3l7lwK41cQ",
    "outputId": "13c16767-9bd7-4c8d-9eb4-2a66f1fcf98d"
   },
   "outputs": [],
   "source": [
    "corr = X_train.corr()\n",
    "print(X_train.shape)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_title(\"Heatmap of the correlation structure\")\n",
    "sn.heatmap(\n",
    "    corr,\n",
    "    mask=np.zeros_like(corr, dtype=np.bool),\n",
    "    cmap=sn.diverging_palette(220, 10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "7c6zgbwk5FAz",
    "outputId": "e194bc3a-1503-4917-fbd8-94c8bc35af4c"
   },
   "outputs": [],
   "source": [
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(X_train, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AThRYu9x5GfR"
   },
   "source": [
    "This is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45ViRnKDXIyB"
   },
   "source": [
    "---\n",
    "### Initial Experiments - SVC\n",
    "\n",
    "To get an idea if further feature preprocessing or selection steps are required we will quickly fit an SVM to the data and inspect the train and test error as estimates by running a 10-fold cross validation. As the SVM is sensitive to the scale of the data we will first standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "svc = SVC(random_state=1234, max_iter = -1)\n",
    "pip = Pipeline(steps=[('SC',sc), ('SVC', svc)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = { 'SVC__C':[1,3], 'SVC__kernel':['rbf'], \n",
    "              'SVC__gamma':[1, 0.5],\n",
    "             'SVC__decision_function_shape':['ovo']}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=KFold(n_splits=5, random_state=1234),\n",
    "                   return_train_score=True, verbose=100, n_jobs= -1)\n",
    "clf.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)\n",
    "\n",
    "print('Mean CV test score for the best estimator: ')\n",
    "max_id = np.argmax(clf.cv_results_['mean_test_score'])\n",
    "print(clf.cv_results_['mean_test_score'][max_id])\n",
    "print(' ')\n",
    "print('Std CV test score for the best estimator: ')\n",
    "print(clf.cv_results_['std_test_score'][max_id])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score for the best estimator: ')\n",
    "print(clf.cv_results_['mean_train_score'][max_id])\n",
    "print(' ')\n",
    "print('Std CV train score for the best estimator: ')\n",
    "print(clf.cv_results_['std_train_score'][max_id])\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is that for many folds the train accuracy is 1, while the test accuracy score is much lower. This implies that our current approach is subject to overfitting. For that reason we will use a well-known recursive feature selection approach to determine the most important features. We will use the feature importance determined by a RandomForestClassifier as a basis and run a 10-fold cross validation to determine the optimal number of features to keep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hbe2PpuKXxfe",
    "outputId": "fe5d61aa-83d8-4a70-ddc3-80870e1564b7"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=1000, random_state=1234)\n",
    "rfe = RFECV(estimator=rfc, verbose = 1, cv=KFold(n_splits=10, random_state=1234))\n",
    "rfe.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us inspect the results that are the number of features determined to be optimal and which features those are in fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#_features:', rfe.n_features_)\n",
    "print('support:', rfe.support_)\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "X_train_rfe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.ranking_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### SVC with reduced feature set\n",
    "\n",
    "We see that recursive feature selection determined 9 features to be the optimal number. This is way less than the orginal 17 we had. Hence, let us check how the SVM now performs on that subset of features. Again we include a standardization step in the pipeline for previously mentioned reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "svc = SVC(random_state=1234, max_iter = -1)\n",
    "pip = Pipeline(steps=[('SC',sc), ('SVC', svc)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = { 'SVC__C':[1,2,3], 'SVC__kernel':['rbf'], \n",
    "              'SVC__gamma':[1, 0.75,  0.5, 0.4, 0.3, 0.25],\n",
    "             'SVC__decision_function_shape':['ovo']}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=KFold(n_splits=10, random_state=1234),\n",
    "                   return_train_score=True, verbose=1, n_jobs= -1)\n",
    "clf.fit(np.array(X_train_rfe), np.array(y_train))\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TfV8m5eLxlK"
   },
   "outputs": [],
   "source": [
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)\n",
    "\n",
    "print('Mean CV test score for the best estimator: ')\n",
    "max_id = np.argmax(clf.cv_results_['mean_test_score'])\n",
    "print(clf.cv_results_['mean_test_score'][max_id])\n",
    "print(' ')\n",
    "print('Std CV test score for the best estimator: ')\n",
    "print(clf.cv_results_['std_test_score'][max_id])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score for the best estimator: ')\n",
    "print(clf.cv_results_['mean_train_score'][max_id])\n",
    "print(' ')\n",
    "print('Std CV train score for the best estimator: ')\n",
    "print(clf.cv_results_['std_train_score'][max_id])\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpigH5avm8xL"
   },
   "source": [
    "The results look promising, while we do not get perfect training fits anymore the test accuracy estimate is now much higher than it was before. Also the discrepancy between the train and test score estimate based on the 10-fold cross validation and the standard deviation estimate of the scores is much lower. Hence, it seems that we were able to reduce the issue of overfitting drastically. However there is still quite a difference. So let us force our classifier to use a larger regularization parameter C (drastically try 3 and upwards) by setting the scope of the grid search accordingly and check how the results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "svc = SVC(random_state=1234, max_iter = -1)\n",
    "pip = Pipeline(steps=[('SC',sc), ('SVC', svc)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = { 'SVC__C':[2.75,3, 3.25, 4,5], 'SVC__kernel':['rbf'], \n",
    "              'SVC__gamma':[1, 0.75, 0.6, 0.55,  0.5, 0.4, 0.3, 0.25],\n",
    "             'SVC__decision_function_shape':['ovo', 'ovr']}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=KFold(n_splits=10, random_state=1234),\n",
    "                   return_train_score=True, verbose=1, n_jobs= -1)\n",
    "clf.fit(np.array(X_train_rfe), np.array(y_train))\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)\n",
    "\n",
    "print('Mean CV test score for the best estimator: ')\n",
    "max_id = np.argmax(clf.cv_results_['mean_test_score'])\n",
    "print(clf.cv_results_['mean_test_score'][max_id])\n",
    "print(' ')\n",
    "print('Std CV test score for the best estimator: ')\n",
    "print(clf.cv_results_['std_test_score'][max_id])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score for the best estimator: ')\n",
    "print(clf.cv_results_['mean_train_score'][max_id])\n",
    "print(' ')\n",
    "print('Std CV train score for the best estimator: ')\n",
    "print(clf.cv_results_['std_train_score'][max_id])\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those results look even better in terms especially of the ratio of the test score accuracy estimate and the associated standard deviation estimate. Hence, we will construct a submission based on that one.\n",
    "\n",
    "---\n",
    "\n",
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_rfe)\n",
    "submission[\"y\"] = y_pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wD_P3gKvc9NG"
   },
   "source": [
    "---\n",
    "\n",
    "## Export data\n",
    "\n",
    "We finally use the Google Colab API to download our submission data frame in from of an csv, that we can submit to the submission platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WNhRwnu7djcg"
   },
   "outputs": [],
   "source": [
    "ts = str(datetime.datetime.utcnow())\n",
    "ts = ts.replace(' ', '_')\n",
    "Filename = 'submission_name'\n",
    "fname = Filename+ts+'.csv'\n",
    "\n",
    "with open(fname, 'w') as f:\n",
    "  submission.to_csv(f, float_format='%.64f', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Intro2ML_Project2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}