{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Intro2ML_Project1B.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "metadata": {
    "id": "dF0copX0ECwY",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "# Project 1B: LinearRegression with feature transformations\n",
    "---\n",
    "\n",
    "This notebook is supposed to be used to provide the solution to the project 1B of the module Introduction to Machine Learning 2019 @ ETHZ.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "metadata": {
    "id": "YTGACEsDir8B",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "## Environmental Set-Up\n",
    "\n",
    "We first set the environment and load the later required packages, as well as fix the random seed globally."
   ]
  },
  {
   "metadata": {
    "id": "tpfh1zCwD9ie",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import sklearn as sl\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.linear_model import Ridge, Lasso, HuberRegressor, LassoLarsIC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.feature_selection import RFECV, RFE, SelectKBest, f_regression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sn.set_context('notebook')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "random.seed(1234)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "VvSSDj_uEqJi",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Load in the data\n",
    "\n",
    "We now use the Google Colab API to load the data and the sample submission from disk into the temproray cloud storage attached to this PaaS (platform as a service) solution to make it accessible."
   ]
  },
  {
   "metadata": {
    "id": "aB-sY89zEwV1",
    "colab_type": "code",
    "outputId": "8e7501ac-2f55-49d2-d235-c83347f1c54a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553195972293,
     "user_tz": -60,
     "elapsed": 22033,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "ok": true,
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "status": 200,
       "status_text": ""
      }
     },
     "base_uri": "https://localhost:8080/",
     "height": 142
    }
   },
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "03aORSaVU3lm",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "\n",
    "---\n",
    "## Project 1B\n",
    "\n",
    "The following section now solves the project 1B of the Introduction to Machine Learning course 2019..\n",
    "\n",
    "---\n",
    "\n",
    "### Formatting the data\n",
    "\n",
    "Although the data is loaded we format it to have it in the handy pandas dataframe format."
   ]
  },
  {
   "metadata": {
    "id": "Jlb-PJ3iXe0F",
    "colab_type": "code",
    "outputId": "8b443ed8-80ca-4e09-f1a9-47e6d592acad",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553195974744,
     "user_tz": -60,
     "elapsed": 736,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Get sample prediction file format.\n",
    "Sample predictions will be simply replaced with the ones obtained from the\n",
    "custom model.\n",
    "''' \n",
    "\n",
    "submission = pd.read_csv('sample.csv', header=None, float_precision='high')\n",
    "submission.head()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "zFhCErVRWFZA",
    "colab_type": "code",
    "outputId": "d890719a-fe9b-4dd1-e2e4-dfb44fcb4618",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553197177106,
     "user_tz": -60,
     "elapsed": 735,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    }
   },
   "cell_type": "code",
   "source": [
    "# Get train data\n",
    "train = pd.read_csv('train.csv', index_col=0, float_precision='high')\n",
    "train.head()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "FN7IZdRowm85",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "We quickly inspect the shape of the data to make sure the data has been correctly loaded and casted into a pandas data frame."
   ]
  },
  {
   "metadata": {
    "id": "u1I0RhruXV1m",
    "colab_type": "code",
    "outputId": "ec7fd825-7a90-43a2-8310-0961828f3b3b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553195994268,
     "user_tz": -60,
     "elapsed": 719,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "cell_type": "code",
   "source": [
    "train.shape"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "fG-c65blwvEi",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "That looks very good. We seperate the label from the features for the sake of handiness of our implementations and data handling in the following."
   ]
  },
  {
   "metadata": {
    "id": "S7kMpKNeZRfn",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "X_train = train.iloc[:, 1:]\n",
    "y_train = train.iloc[:, 0]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "v08F5piwGDeY",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Feature Engineering\n",
    "\n",
    "As required by the task we construct additional features that are non-linear transformations of our given features and add those to the training data frame. Those are namely the quadratic form of the 5 predictor variables, as well as e to the power of those and the cosine of them. Finally we add a constant bias feature to the set of predictors."
   ]
  },
  {
   "metadata": {
    "id": "h49IPf3DGmPL",
    "colab_type": "code",
    "outputId": "0a188d5a-5214-45eb-a2b1-abd3c6ec82bd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553197183581,
     "user_tz": -60,
     "elapsed": 916,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    }
   },
   "cell_type": "code",
   "source": [
    "# Add quadratic version of the features\n",
    "for i in range(5):\n",
    "  feature_name = 'phi'+str(X_train.shape[1]+1)\n",
    "  X_train[feature_name] = X_train.iloc[:,i]**2\n",
    "\n",
    "# Add exponential version of the features\n",
    "for i in range(5):\n",
    "  feature_name = 'phi'+str(X_train.shape[1]+1)\n",
    "  X_train[feature_name] = np.exp(X_train.iloc[:,i])\n",
    "  \n",
    "# Add cosine version of the features\n",
    "for i in range(5):\n",
    "  feature_name = 'phi'+str(X_train.shape[1]+1)\n",
    "  X_train[feature_name] = np.cos(X_train.iloc[:,i])\n",
    "\n",
    "# Add constant feature\n",
    "\n",
    "feature_name = 'phi'+str(X_train.shape[1]+1)\n",
    "X_train[feature_name] = 1\n",
    "  \n",
    "  \n",
    "X_train.describe()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "5DNPlDTpvwpH",
    "colab_type": "code",
    "outputId": "f5dd8655-25bc-4c78-f949-657038dcff47",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553197222696,
     "user_tz": -60,
     "elapsed": 766,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    }
   },
   "cell_type": "code",
   "source": [
    "y_train.describe()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "WOKrUt4dZYYt",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### Model Fitting and Selection\n",
    "\n",
    "Since the data is now loaded, we start with the simpliest model and fit a linear regression model. Note since this model has no hyperparameters we do not need any grid search approaches over a set of those. Nonetheless, we will use the respective class from the sklearn package to handily perform a 10 fold cross validation to get an idea of the performance of the model.\n"
   ]
  },
  {
   "metadata": {
    "id": "rc3IPttZzC0s",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "# We first define the score function as the RMSE since this is the metric of \n",
    "# grading defined by the task\n",
    "def rmse(y, y_pred):\n",
    "  RMSE = mean_squared_error(y, y_pred)**0.5\n",
    "  return(RMSE)\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "fopPqM1UJsQ5",
    "colab_type": "code",
    "outputId": "8f5ef9c9-d4c6-48c4-e1a8-bc1c9329f5ec",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553080340899,
     "user_tz": -60,
     "elapsed": 782,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    }
   },
   "cell_type": "code",
   "source": [
    "LR = LinearRegression()\n",
    "pip = Pipeline(steps=[('LR', LR)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'LR__fit_intercept':[False]}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=KFold(n_splits=10, random_state=1234), \n",
    "                   scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train.iloc[:,0:5], y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "iayXrvcqamfe",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "We see that the performance is not quite satisfactory. As for reference this value would allow to pass the easy baseline, but would yet require a decrease by roughly 4% to pass the medium baseline. More sophisticated approaches are required."
   ]
  },
  {
   "metadata": {
    "id": "9oWHccYxjOdn",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Ridge Regression\n",
    "\n",
    "One possible explanation for the rather bad performance of our linear regression model is that it captures to much of the random noise. Thus, we will now consider a different approach and try to make the solution less sensitive to noise by using a Ridge Regression approach, which due to the L2 regularization is less prone to overfit than linear regression. This time we have a hyperparameter namely the regularization parameter to tune and we will do so using a grid search approach performing again a 10 fold cross validation.\n"
   ]
  },
  {
   "metadata": {
    "id": "hbnxpvhVY4mk",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "RR = Ridge(fit_intercept=False, random_state=1234)\n",
    "pip = Pipeline(steps=[('RR', RR)])\n",
    "\n",
    "# Define GridSearch parameter using the common applied practise we choose\n",
    "# different magnitudes\n",
    "param_dict = {'RR__alpha':[0.1, 1 , 10, 100, 1000]}"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "7COUZbfIZwRe",
    "colab_type": "code",
    "outputId": "e50035dc-aa41-4e35-bc2c-08ac48363f71",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553080956294,
     "user_tz": -60,
     "elapsed": 782,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    }
   },
   "cell_type": "code",
   "source": [
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=KFold(n_splits=10, random_state=1234), \n",
    "                   scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "colab_type": "text",
    "id": "5S4nQO2KjhvT"
   },
   "cell_type": "markdown",
   "source": [
    "We see that the best estimator is fitted for $\\alpha = 100$.  We see that the determined mean cross validation error is roughly 9.971 and would hence be way below the hard baseline. Nonetheless, we see that this estimate is obtained with a the highest variance across the other test models with different $\\alpha$'s. Nonetheless, we will give it a shot and use the coefficients from the model fitted to the whole data with the regularization parameter $\\alpha=100$ and submit the those to see how the model performs on the public test set."
   ]
  },
  {
   "metadata": {
    "id": "h90ZsLRjkbsp",
    "colab_type": "code",
    "outputId": "0e405951-7cd6-4aaa-8625-c82b6f570f02",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553081259041,
     "user_tz": -60,
     "elapsed": 629,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract coefficients\n",
    "fitted_pip = clf.best_estimator_\n",
    "RR_coefs = fitted_pip.named_steps['RR'].coef_\n",
    "RR_coefs"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "BvufBuVI24ma",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "Note that the functionality to transform that array of coefficients into the desired csv submission format is given in the submission chapter of that notebook."
   ]
  },
  {
   "metadata": {
    "id": "sbqZJDZblos8",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### Lasso\n",
    "\n",
    "The results are better but not yet satisfactory, in fact we obtain a public test score of 10.343 using this approach. \n",
    "\n",
    "However, it seems that the regularization yielded better results, backing our impression that the data is quite noisy and our current models capture to much of that random noice. \n",
    "\n",
    "Hence we will use linear model using the L1 regularization, which will generally drive down the weights more quickly to 0 and hence making our model more stable and less likely to overfit.  We thereby hope to drive down the variance of our model, which seems to be present considering the great deviance between the public test score and our mean cross validation score and the standard errors of cross validation scores."
   ]
  },
  {
   "metadata": {
    "id": "ZzRIRQZtmFYc",
    "colab_type": "code",
    "outputId": "e2464772-6b25-4e3f-e9da-cd645d8d01b8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553196049381,
     "user_tz": -60,
     "elapsed": 3080,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    }
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "Ls = Lasso(fit_intercept=False, max_iter=100000, random_state = 1234)\n",
    "pip = Pipeline(steps=[('Lasso', Ls)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'Lasso__alpha':[0.001, 0.1, 0.2, 0.5, 1, 1.5, 2, 5, 10]}\n",
    "\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=KFold(n_splits=10, random_state=1234), scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "I2bQJy6GtuaQ",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "clf.cv_results_"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "z1nFQKoynn5v",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "We see that the optimal regularization parameter according to our cross validation error estimates for the RMSE of the model is 0.1. The reported mean cross validation error estimate looks better than for Ridge Regression, and also the standard error of the RMSE obtained for the different folds is slightly higher than for Ridge regression.\n",
    "\n",
    "However, we will construct a submission based on the weights obtained from the Lasso model fitted to the whole data set with $\\alpha$=0.1 and check the performance of that model on the public test set."
   ]
  },
  {
   "metadata": {
    "id": "E0e0tpaCn5Ag",
    "colab_type": "code",
    "outputId": "d0614e68-0f88-4620-e9a4-7608d176ae3e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553082239291,
     "user_tz": -60,
     "elapsed": 736,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    }
   },
   "cell_type": "code",
   "source": [
    "fitted_pip = clf.best_estimator_\n",
    "Lasso_coefs = fitted_pip.named_steps['Lasso'].coef_\n",
    "Lasso_coefs"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "tFbfF0fwuRaR",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "The public test score is better than what we obtained for Ridge regression and with 10.1123 way below the medium baseline but yet above the hard baseline.\n",
    "\n",
    "Nonetheless the fact that Lasso shrunk down the weights of 8 features to 0 and thus excluded them in some way and the fact that it yielded a better public test score as well as a better cross validation error score, suggests that our model is still subject to high-variance and a more sophistacted feature selection might be promising.\n",
    "\n",
    "Before doing so we will however try using a larger $\\alpha \\geq 0.8$ as this would also provide a more drastic feature selection by shrinking down more weights to zero."
   ]
  },
  {
   "metadata": {
    "id": "64tFBBfjsEEv",
    "colab_type": "code",
    "outputId": "c1379b63-b2c1-42e9-8f00-b6500942b05b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553197397907,
     "user_tz": -60,
     "elapsed": 1067,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    }
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "Ls = Lasso(fit_intercept=False, max_iter=100000, random_state = 1234)\n",
    "pip = Pipeline(steps=[('Lasso', Ls)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'Lasso__alpha':[0.7,0.8, 0.9,1, 1.5, 2, 5, 10]}\n",
    "\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=KFold(n_splits=10, random_state=1234), \n",
    "                   scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "NwDQiW6ms1Ap",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "The results look promising since the mean CV test score is still quite good but the associated standard error is slightly reduced. So let us have a look at the coefficents."
   ]
  },
  {
   "metadata": {
    "id": "bcf7kUTbtD5t",
    "colab_type": "code",
    "outputId": "73c880fa-6407-4cb5-afb3-83e99f3bfe71",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553196799978,
     "user_tz": -60,
     "elapsed": 805,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    }
   },
   "cell_type": "code",
   "source": [
    "fitted_pip = clf.best_estimator_\n",
    "Lasso_coefs = fitted_pip.named_steps['Lasso'].coef_\n",
    "Lasso_coefs"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "H_8GihrKtI69",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "We see that we are left with 5 features, one linear, three quadratic and 2 exponential features. Since this model is less complex we anticipate more bias but less variance in the model and hence less deviation between the cv test error estimate and the actual test error. Let us verify that by creating a submission using those coefficents."
   ]
  },
  {
   "metadata": {
    "id": "i6vepofFr2Nf",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Manual Feature Selection\n",
    "\n",
    "Recalling, how the features were constructed we will first construct different subset of features inspired by the form."
   ]
  },
  {
   "metadata": {
    "id": "WrnvtD2IJL7l",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "However, first let us inspect the correlation structure of the features to see if have problem the issue of multicollinearity, which would lead to very unstable models. This could be one cause for fact that our models still were subject to overfitting indicated by the great deviance between our cross validation error estimate and the public test score."
   ]
  },
  {
   "metadata": {
    "id": "SDAHC5lvJvT5",
    "colab_type": "code",
    "outputId": "815eed89-4536-4e3f-fc1e-bd0e64b76793",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553083113138,
     "user_tz": -60,
     "elapsed": 1785,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    }
   },
   "cell_type": "code",
   "source": [
    "corr = X_train.corr()\n",
    "print(X_train.shape)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_title(\"Heatmap of the correlation structure\")\n",
    "sn.heatmap(\n",
    "    corr,\n",
    "    mask=np.zeros_like(corr, dtype=np.bool),\n",
    "    cmap=sn.diverging_palette(220, 10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "aHYUllGjMRBs",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "What we see is that $x_1,...,\\phi_{10}$ are fairly strongly correlated with $\\phi_{11},...,\\phi{10}$, hence we will try out a setting where we only include the $x_1,..., \\phi_{10}$.\n",
    "\n",
    "---\n",
    "##### Quadratic Regression\n",
    "\n",
    "Doing so yield a quadratic regression model. Before fitting the model let us check if removing all other predictors yields a nicer correlation structure between the predictors."
   ]
  },
  {
   "metadata": {
    "id": "RchzogI5NVBj",
    "colab_type": "code",
    "outputId": "648061d7-61cb-4581-da60-9765b08e6704",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553083172756,
     "user_tz": -60,
     "elapsed": 2130,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_quad = X_train[['x1', 'x2', 'x3', 'x4', 'x5','phi6', 'phi7', 'phi8', \n",
    "                        'phi9', 'phi10', 'phi21']]\n",
    "corr = X_train_quad.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_title(\"Heatmap of the correlation structure\")\n",
    "sn.heatmap(\n",
    "    corr,\n",
    "    mask=np.zeros_like(corr, dtype=np.bool),\n",
    "    cmap=sn.diverging_palette(220, 10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "2zhw2OoC-Qzm",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "This is very much the case as we dont see any strongly correlated features any longer. Hence we will now fit a Ridge Regression Model to this set of features."
   ]
  },
  {
   "metadata": {
    "id": "C-z4ZyAXNh0o",
    "colab_type": "code",
    "outputId": "1150235c-ed3e-4a47-8a9c-680a6981c71d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553083326036,
     "user_tz": -60,
     "elapsed": 848,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    }
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "RR = Ridge(fit_intercept=False, random_state=1234, max_iter=10000)\n",
    "pip = Pipeline(steps=[('RR', RR)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'RR__alpha':[0, 1, 10, 100, 1000]}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=KFold(n_splits=10, random_state=1234), \n",
    "                   scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train_quad, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "euWjwqt9-1yD",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "The results look better in a sense that the standard error of our cross validation scores is less in comparison to our previous approaches. The score it self however are remarkably higher. This is not suprising as by removing a set of variables we increase the bias, while reducing the variance. However the reported score would be still way beyond the hard baseline, if we get a similar performance on the private test with that model. We will construct the array of coefficients and  submit such to get an idea of the performance on the public test set."
   ]
  },
  {
   "metadata": {
    "id": "LoPC314ORDR7",
    "colab_type": "code",
    "outputId": "38f83e69-076f-4184-fb76-4d178591350f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553083538201,
     "user_tz": -60,
     "elapsed": 774,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    }
   },
   "cell_type": "code",
   "source": [
    "fitted_pip = clf.best_estimator_\n",
    "QuadR_coefs = fitted_pip.named_steps['RR'].coef_\n",
    "QuadR_coefs = np.concatenate((QuadR_coefs[0:10], np.repeat(0,10), np.array([QuadR_coefs[10]])),axis=0)\n",
    "QuadR_coefs\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "ek2eigPcAGXM",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "The results are better than what we had for the  Lasso regression on the whole data set but yet not satisfactory. We will aim for even more regularization inspired by the still remarkable gap between the cross validation error estimate and the public test score by replacing the Ridge regression with the Lasso."
   ]
  },
  {
   "metadata": {
    "id": "kZ3wNC83AX8Z",
    "colab_type": "code",
    "outputId": "84568177-db65-4356-bf2c-1770b36eb761",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553083849653,
     "user_tz": -60,
     "elapsed": 2369,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    }
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "Ls = Lasso(fit_intercept=False, random_state=1234, max_iter=10000)\n",
    "pip = Pipeline(steps=[('Lasso', Ls)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'Lasso__alpha':[0.01, 0.1, 0.5, 1]}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=KFold(n_splits=10, random_state=1234), \n",
    "                   scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train_quad, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "Qyru1bDIA6l1",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "According to results from our cross validation the Lasso performs better to a tiny degree.\n",
    "Let us inspect the estimated coefficents."
   ]
  },
  {
   "metadata": {
    "id": "ZbMB6ryRBNZH",
    "colab_type": "code",
    "outputId": "0a290eca-fc72-4dda-ce58-4fa251a107f2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553084054599,
     "user_tz": -60,
     "elapsed": 961,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    }
   },
   "cell_type": "code",
   "source": [
    "fitted_pip = clf.best_estimator_\n",
    "QuadL_coefs = fitted_pip.named_steps['Lasso'].coef_\n",
    "QuadL_coefs = np.concatenate((QuadL_coefs[0:10], np.repeat(0,10), np.array([QuadL_coefs[10]])),axis=0)\n",
    "QuadL_coefs"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "kHxQI5QqBjvw",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "We see that Lasso basically excluded $\\phi_7$. We will construct a submission based on those as well to see if even larger regularization provides a public test score that is more consistent with the error estimates in the cross validation. With a public test score of roughly 10.090 this is the case. However it not satisfactory. We will now without much of further explanation check the other obvious subsets of the features in the following in a similar manner."
   ]
  },
  {
   "metadata": {
    "id": "HFkoy-jpTBZv",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "##### Exponential Function Fitting\n",
    "\n",
    "We will now try only using $x_1,...,x_5,\\phi_{11},...,\\phi_{15}$ now."
   ]
  },
  {
   "metadata": {
    "id": "cHmvEVUnTP2q",
    "colab_type": "code",
    "outputId": "70c6156d-ed06-4a15-f019-bbdcd81f1993",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553084651303,
     "user_tz": -60,
     "elapsed": 1417,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_exp = X_train[['x1', 'x2', 'x3', 'x4', 'x5','phi11', 'phi12', 'phi13', 'phi14', 'phi15', 'phi21']]\n",
    "corr = X_train_exp.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_title(\"Heatmap of the correlation structure\")\n",
    "sn.heatmap(\n",
    "    corr,\n",
    "    mask=np.zeros_like(corr, dtype=np.bool),\n",
    "    cmap=sn.diverging_palette(220, 10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "CqgrL1RlUJNA",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "We see a quite strong correlation structure between constructed non-linear features and the constructed features.  We will also fit a Lasso Regression here and look at the results."
   ]
  },
  {
   "metadata": {
    "id": "TB3ycscnUkcT",
    "colab_type": "code",
    "outputId": "a52d0e9c-5a16-4d6e-d11e-6b0f2c4f4676",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553085174348,
     "user_tz": -60,
     "elapsed": 951,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    }
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "Ls = Lasso(fit_intercept=False, random_state=1234, max_iter=10000)\n",
    "pip = Pipeline(steps=[('Lasso', Ls)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'Lasso__alpha':[0.5, 1, 2, 5, 10]}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=KFold(n_splits=10, random_state=1234),\n",
    "                   scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train_exp, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "Cc2kv7oVVAQ8",
    "colab_type": "code",
    "outputId": "d7b461b2-971e-49b6-ecd3-3a3590f48425",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553085185408,
     "user_tz": -60,
     "elapsed": 828,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    }
   },
   "cell_type": "code",
   "source": [
    "fitted_pip = clf.best_estimator_\n",
    "ExpL_coefs = fitted_pip.named_steps['Lasso'].coef_\n",
    "ExpL_coefs = np.concatenate((ExpL_coefs[0:5], np.repeat(0,5), ExpL_coefs[5:10],np.repeat(0,5), np.array([ExpL_coefs[10]])),axis=0)\n",
    "ExpL_coefs"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "kE7eoERmH2Fj",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "The  scores look promosing especially because the train and test errors are almost the same, the standard error of the cross validation is not too high and due to the strong regualization we are left with a very simple model that is not as likely to overfit than more complex models. \n",
    "\n",
    "Since this model also yields a public test score of 10.009, and thereby the smallest difference between the cross validation error estimate and the one obtained for public test set, it is a promising candidate for the final submission."
   ]
  },
  {
   "metadata": {
    "id": "YpJNUO4hV86M",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "##### Cosine Regression\n",
    "\n",
    "Last but not least we also consider only a cosine regression.\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "id": "X1t75wo0W_jJ",
    "colab_type": "code",
    "outputId": "2b1e2acd-685c-4b8a-bc0b-26ab1e9fddf1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1551781209333,
     "user_tz": -60,
     "elapsed": 1642,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_cos = X_train[['x1', 'x2', 'x3', 'x4', 'x5','phi16', 'phi17', 'phi18', 'phi19', 'phi20', 'phi21']]\n",
    "corr = X_train_cos.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_title(\"Heatmap of the correlation structure\")\n",
    "sn.heatmap(\n",
    "    corr,\n",
    "    mask=np.zeros_like(corr, dtype=np.bool),\n",
    "    cmap=sn.diverging_palette(220, 10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "xQ37nQ8iXXVb",
    "colab_type": "code",
    "outputId": "77369b5d-9695-4655-a0ef-cd8e9d453bbe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1551781267975,
     "user_tz": -60,
     "elapsed": 478,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    }
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "RR = Ridge(fit_intercept=False, random_state=1234, max_iter=10000)\n",
    "pip = Pipeline(steps=[('RR', RR)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'RR__alpha':[0, 0.1, 1, 100, 1000]}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=5, scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train_cos, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "N6X4Ccu0X77B",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "The reported scores are less promosing although the associated standard errors are also way less.\n",
    "\n",
    "---\n",
    "##### Quadratic-Exponential Regression\n",
    "\n",
    "We will now also consider the other subsets starting with that having the exponential, linear and quadratic terms included."
   ]
  },
  {
   "metadata": {
    "id": "9uSZTzGqYk-p",
    "colab_type": "code",
    "outputId": "f29129bb-285a-404b-87a8-15fcc2d75a9f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1551781550582,
     "user_tz": -60,
     "elapsed": 1467,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_exp_quad = X_train[['x1', 'x2', 'x3', 'x4', 'x5','phi6', 'phi7', 'phi8', 'phi9', 'phi10','phi11', 'phi12', 'phi13', 'phi14', 'phi15', 'phi21']]\n",
    "corr = X_train_exp_quad.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_title(\"Heatmap of the correlation structure\")\n",
    "sn.heatmap(\n",
    "    corr,\n",
    "    mask=np.zeros_like(corr, dtype=np.bool),\n",
    "    cmap=sn.diverging_palette(220, 10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "rTuVXtQBY9Yv",
    "colab_type": "code",
    "outputId": "5cf08cb0-5d1e-4162-dc7f-e8f589b89bb0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1551782873161,
     "user_tz": -60,
     "elapsed": 531,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    }
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "RR = Ridge(fit_intercept=False, random_state=1234, max_iter=10000)\n",
    "pip = Pipeline(steps=[('RR', RR)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'RR__alpha':[100, 200, 300]}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=5, scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train_exp_quad, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "o2YVHn33ZcXo",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "We very similar performance estimates by the CV than we got for just including the exponential and linear features. This suggests that it is not worth to include the quadratic features, when the exponential features are already included.\n",
    "\n",
    "---\n",
    "##### Quadratic and Cosine Regression"
   ]
  },
  {
   "metadata": {
    "id": "ezakLpzheJ3S",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "rWwl9-MHZwPc",
    "colab_type": "code",
    "outputId": "cba7f893-1752-4003-8289-1274071bdddc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1551781871972,
     "user_tz": -60,
     "elapsed": 1726,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_cos_quad = X_train[['x1', 'x2', 'x3', 'x4', 'x5','phi6', 'phi7', 'phi8', 'phi9', 'phi10','phi16', 'phi17', 'phi18', 'phi19', 'phi20', 'phi21']]\n",
    "corr = X_train_cos_quad.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_title(\"Heatmap of the correlation structure\")\n",
    "sn.heatmap(\n",
    "    corr,\n",
    "    mask=np.zeros_like(corr, dtype=np.bool),\n",
    "    cmap=sn.diverging_palette(220, 10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "uj1ZgELTaHa2",
    "colab_type": "code",
    "outputId": "8ea28ca6-a9d4-415e-c7c3-9bb832a4ce2b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1551781939782,
     "user_tz": -60,
     "elapsed": 618,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    }
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "RR = Ridge(fit_intercept=False, random_state=1234, max_iter=10000)\n",
    "pip = Pipeline(steps=[('RR', RR)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'RR__alpha':[0, 0.1, 1, 10, 100, 200, 300, 500, 1000]}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=5, scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train_cos_quad, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "wd7twgOIabOV",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "The results are very similar to the ones we obtained from just using the quadratic and linear features. The optimal penalizing parameter $\\alpha$ changes, however the associated mean CV scores and the standard errors are of the same margin. Hence it does not seem to be promising to include also the cosine features if we already use the quadratic and linear features.\n",
    "\n",
    "---\n",
    "\n",
    "##### Cosine and Exponential Regression"
   ]
  },
  {
   "metadata": {
    "id": "i6fckRlQbJZW",
    "colab_type": "code",
    "outputId": "d9c06ca8-614d-4075-eebf-d218516fc480",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1551782250665,
     "user_tz": -60,
     "elapsed": 1489,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_cos_exp = X_train[['x1', 'x2', 'x3', 'x4', 'x5','phi11', 'phi12', 'phi13', 'phi14', 'phi15','phi16', 'phi17', 'phi18', 'phi19', 'phi20', 'phi21']]\n",
    "corr = X_train_cos_exp.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_title(\"Heatmap of the correlation structure\")\n",
    "sn.heatmap(\n",
    "    corr,\n",
    "    mask=np.zeros_like(corr, dtype=np.bool),\n",
    "    cmap=sn.diverging_palette(220, 10, as_cmap=True),\n",
    "    square=True,\n",
    "    ax=ax)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "VvvzHg4NbY3j",
    "colab_type": "code",
    "outputId": "96a8614e-8edb-4585-cee9-227c53f40ed6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1551782261621,
     "user_tz": -60,
     "elapsed": 745,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    }
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "RR = Ridge(fit_intercept=False, random_state=1234, max_iter=10000)\n",
    "pip = Pipeline(steps=[('RR', RR)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'RR__alpha':[0, 0.1, 1, 10, 100, 200, 300, 500, 1000]}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=5, scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train_cos_exp, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "qQpJ-eX5bnNB",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "The results are way worse then ones we got for just using the linear features and the exponentially transformed versions of those. Thus it seems like that including the cosine features do not yield any benefit but rather make the performance worse.\n",
    "\n",
    "### Automated Feature Selection\n",
    "\n",
    "##### Support Vector Regression with recursive Feature Selection\n",
    "\n",
    "In the following we aim for even more robust solutions by using Support Vector Regression following a recursive feature selection approach, where features are selected according to the importance measure determined by a preceding Random Forest Regression."
   ]
  },
  {
   "metadata": {
    "id": "TUb9D7mSzVB3",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "# Define Regressors\n",
    "SVR = LinearSVR(fit_intercept=False, random_state=1234, max_iter=10000)\n",
    "RFR = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=1234)\n",
    "ETR = ExtraTreesRegressor(n_estimators=100, random_state=1234, oob_score=True)\n",
    "\n",
    "# Run Recursive Feature Elimination with rmse as scor\n",
    "RFE_SVR = RFECV(SVR, cv=10, scoring=rmse_scorer)\n",
    "RFE_SVR = RFE_SVR.fit(X_train, y_train)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "ckoboFBddaa8",
    "colab_type": "code",
    "outputId": "56f09802-dcd7-4671-809a-c18bee631891",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405841827,
     "user_tz": -60,
     "elapsed": 642,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    }
   },
   "cell_type": "code",
   "source": [
    "mask = RFE_SVR.support_\n",
    "mask"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "E1hYarBBtKOj",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "We see that the recursive backward selection determined to only use $x_2, x_1^2,x_5^2,exp(x_1), exp(x_3), cos(x_2), cos(x_4)$ and the intercept. That are the features refering to columns with the indices: 1,5,9,10,12,16,18, 20.\n",
    "\n",
    "Let us check the respective cv_test scores for the SVR fitted on that data set i.e. the mean score and the standard error of it."
   ]
  },
  {
   "metadata": {
    "id": "DDhPGomgvGue",
    "colab_type": "code",
    "outputId": "8a968fe7-0e98-4a50-9723-04746ede9d80",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405777302,
     "user_tz": -60,
     "elapsed": 636,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    }
   },
   "cell_type": "code",
   "source": [
    "RFE_SVR.grid_scores_"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "BUx1n4K9v2vm",
    "colab_type": "code",
    "outputId": "0dc63c16-d6ec-4f8b-bf5b-f5d48fc24f73",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405797886,
     "user_tz": -60,
     "elapsed": 854,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "cell_type": "code",
   "source": [
    "RFE_SVR.estimator_.coef_"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "Q_GtA4o9wTIK",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "Let us take those coefficients and just add one submission to get an idea how that would perform."
   ]
  },
  {
   "metadata": {
    "id": "lrLhmcW2wc5-",
    "colab_type": "code",
    "outputId": "8def8fad-b712-4828-90c4-94c207eb80c1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405862916,
     "user_tz": -60,
     "elapsed": 871,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    }
   },
   "cell_type": "code",
   "source": [
    "RFE_SVR_coefs = []\n",
    "coef_idcs = [1,5,9,10,12,16,18, 20]\n",
    "tmp=0\n",
    "for i in range(21):\n",
    "  if i in coef_idcs:\n",
    "    RFE_SVR_coefs.append(RFE_SVR.estimator_.coef_[tmp])\n",
    "    tmp += 1\n",
    "  else:\n",
    "    RFE_SVR_coefs.append(0)\n",
    "\n",
    "RFE_SVR_coefs = np.array(RFE_SVR_coefs)\n",
    "RFE_SVR_coefs"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "n9Qiw_xDyY-k",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "#### RidgeRegression with Recursive Feature Selection\n"
   ]
  },
  {
   "metadata": {
    "id": "3I83lZNlye_9",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "# Define Regressors\n",
    "RR = Ridge(fit_intercept=False, alpha=100)\n",
    "\n",
    "# Run Recursive Feature Elimination with rmse as scor\n",
    "RFE_RR = RFECV(RR, cv=10, scoring=rmse_scorer)\n",
    "RFE_RR = RFE_RR.fit(X_train, y_train)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "f1JOwU2SytuR",
    "colab_type": "code",
    "outputId": "b8831629-b8ca-4884-da46-cdc9b1815d24",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405927029,
     "user_tz": -60,
     "elapsed": 645,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    }
   },
   "cell_type": "code",
   "source": [
    "mask = RFE_RR.support_\n",
    "mask"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "ZqrnlOym0a-o",
    "colab_type": "code",
    "outputId": "d24ecce0-c256-46de-93f3-f565dd2d3ea5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405912893,
     "user_tz": -60,
     "elapsed": 862,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "cell_type": "code",
   "source": [
    "RFE_RR.ranking_"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "pkV961Z60e23",
    "colab_type": "code",
    "outputId": "7ea7afdf-ed9c-4480-8da3-a5e8825d423c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405919649,
     "user_tz": -60,
     "elapsed": 909,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    }
   },
   "cell_type": "code",
   "source": [
    "RFE_RR.grid_scores_"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "2l4dxkYqnBdH",
    "colab_type": "code",
    "outputId": "f34b1710-dc4b-4f2f-b779-0902bd756a35",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552406125890,
     "user_tz": -60,
     "elapsed": 572,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "cell_type": "code",
   "source": [
    "print('mean test score:')\n",
    "print(np.max(RFE_RR.grid_scores_))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "qTk9wZhezQuq",
    "colab_type": "code",
    "outputId": "87445169-ff54-4697-ed1e-3f535b3f92c6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405974238,
     "user_tz": -60,
     "elapsed": 613,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    }
   },
   "cell_type": "code",
   "source": [
    "RFE_RR_coefs = []\n",
    "tmp = 0\n",
    "for i in range(21):\n",
    "  if mask[i]:\n",
    "    RFE_RR_coefs.append(RFE_RR.estimator_.coef_[tmp])\n",
    "    tmp += 1\n",
    "  else:\n",
    "    RFE_RR_coefs.append(0)\n",
    "RFE_RR_coefs"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "DRPPLA7L1Vhg",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "#### Extensive Feature Subset Selection GridSearch\n"
   ]
  },
  {
   "metadata": {
    "id": "To0U8dX71a8r",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "# Set pipeline\n",
    "RFR = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=1234)\n",
    "rfe = RFE(RFR)\n",
    "RR = Ridge(fit_intercept=False, random_state=1234, max_iter=1000)\n",
    "pip = Pipeline(steps=[('RFE', rfe),('RR', RR)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'RFE__n_features_to_select':np.arange(0,11)+6,'RR__alpha':[100, 200, 300]}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=5, scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "tn7e5NLjKw3v",
    "colab_type": "code",
    "outputId": "7c726e3e-c191-4d90-b40c-42dc525f0db3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552080976217,
     "user_tz": -60,
     "elapsed": 699,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    }
   },
   "cell_type": "code",
   "source": [
    "mask = clf.best_estimator_.named_steps['RFE'].support_\n",
    "coefs = clf.best_estimator_.named_steps['RR'].coef_\n",
    "\n",
    "RFE_RR_coefs = []\n",
    "tmp = 0\n",
    "for i in range(21):\n",
    "  if mask[i]:\n",
    "    RFE_RR_coefs.append(coefs[tmp])\n",
    "    tmp += 1\n",
    "  else:\n",
    "    RFE_RR_coefs.append(0)\n",
    "np.array(RFE_RR_coefs)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "pXa1oAKRPHvI",
    "colab_type": "code",
    "outputId": "a55becd1-b1a7-4bb5-d729-ea1fbc222f1a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552080997301,
     "user_tz": -60,
     "elapsed": 693,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    }
   },
   "cell_type": "code",
   "source": [
    "mask"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "wnk9I-vIWUYr",
    "colab_type": "code",
    "outputId": "7584fde6-0216-4072-8e6e-b3ffef9d5d0d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405034411,
     "user_tz": -60,
     "elapsed": 46275,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2193
    }
   },
   "cell_type": "code",
   "source": [
    "# Note that because of the because feature 21 is the same for data points the\n",
    "# F-score is mal-defined to avoid an overflow of warnings assessing that issue\n",
    "# we set the following argument.\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set pipeline\n",
    "SKB = SelectKBest(f_regression)\n",
    "RR = Ridge(fit_intercept=True, random_state=1234, max_iter=1000)\n",
    "LR = LinearRegression()\n",
    "SVR = LinearSVR(random_state=1234)\n",
    "pip = Pipeline(steps=[('SKB', SKB),('RR', SVR)])\n",
    "\n",
    "# Define GridSearch parameter\n",
    "param_dict = {'SKB__k':np.arange(1,21), 'RR__C':[0.1,1,2,3,5,10,15,20]}\n",
    "# Run GridSearch\n",
    "clf = GridSearchCV(pip, param_dict, cv=10, scoring=rmse_scorer, return_train_score=True)\n",
    "clf.fit(X_train.iloc[:,:-1], y_train)\n",
    "\n",
    "print('Mean CV test score: ')\n",
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(' ')\n",
    "print('Std CV test score: ')\n",
    "print(clf.cv_results_['std_test_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Mean CV train score: ')\n",
    "print(clf.cv_results_['mean_train_score'])\n",
    "print(' ')\n",
    "print('Std CV train score: ')\n",
    "print(clf.cv_results_['std_train_score'])\n",
    "print(' ')\n",
    "\n",
    "print('Best estimator parameter: ')\n",
    "print(clf.best_params_)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "AEKe7yJXXxX9",
    "colab_type": "code",
    "outputId": "fabc3015-5c21-4fbd-b10a-13db6f6e8e05",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405034413,
     "user_tz": -60,
     "elapsed": 39503,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    }
   },
   "cell_type": "code",
   "source": [
    "print('Test error of best estimator')\n",
    "print(np.max(clf.cv_results_['mean_test_score']))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Test error std of best estimator')\n",
    "print(np.min(clf.cv_results_['std_test_score']))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Train error of best estimator')\n",
    "print(np.max(clf.cv_results_['mean_train_score']))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Train error std of best estimator')\n",
    "print(np.min(clf.cv_results_['std_train_score']))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "36PlIO9FZpIO",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "The metrics look promising, let us inspect which features where selected, that are the 14 ones with the highest score plus the intercept."
   ]
  },
  {
   "metadata": {
    "id": "yT4wxTLIaprI",
    "colab_type": "code",
    "outputId": "3b80db27-1674-41cb-ec43-662b026d94f3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405034415,
     "user_tz": -60,
     "elapsed": 35795,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    }
   },
   "cell_type": "code",
   "source": [
    "best_estimator = clf.best_estimator_\n",
    "scores = best_estimator.named_steps['SKB'].scores_\n",
    "print(scores)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "vI-qsTSBb9iJ",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "Let us check to which features those refer to."
   ]
  },
  {
   "metadata": {
    "id": "ik1vClYOcAmF",
    "colab_type": "code",
    "outputId": "237ce882-74c7-465a-bdee-64e3b3d95ce4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405034415,
     "user_tz": -60,
     "elapsed": 31889,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "cell_type": "code",
   "source": [
    "ind = np.argpartition(scores, -14)[-14:]\n",
    "sorted_idc = np.sort(ind)\n",
    "print(sorted_idc)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "6MBd8P-rcE_G",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "We see that they refer to $x_1,...,x_4,x_1^2, x_3^2,x_5^2, e^x_1,..,e^x_4, cos(x_1),...,cos(x_3), cos(x_5)$ \n",
    "\n",
    "Let us submit the determined coefficients for those"
   ]
  },
  {
   "metadata": {
    "id": "jfIHc3Qtc_K9",
    "colab_type": "code",
    "outputId": "df4214b7-5c54-4f26-9cff-0faaaa76bbd1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1552405034417,
     "user_tz": -60,
     "elapsed": 30201,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    }
   },
   "cell_type": "code",
   "source": [
    "SKB_RR_coefs =[]\n",
    "tmp = 0\n",
    "for i in range(20):\n",
    "  if i in sorted_idc:\n",
    "    SKB_RR_coefs.append(best_estimator.named_steps['RR'].coef_[tmp])\n",
    "    tmp += 1\n",
    "  else:\n",
    "    SKB_RR_coefs.append(0.0)\n",
    "SKB_RR_coefs.append(best_estimator.named_steps['RR'].intercept_)\n",
    "\n",
    "SKB_RR_coefs = np.array(SKB_RR_coefs)\n",
    "SKB_RR_coefs"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "UtZJQsJOcEmj",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### Submission\n",
    "\n",
    "We construct the submission with the choice of respective coefficents from our trials."
   ]
  },
  {
   "metadata": {
    "id": "7DWdmuTccTdn",
    "colab_type": "code",
    "outputId": "869d3ff8-f44b-46f0-84cd-96d58894c280",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1553196278901,
     "user_tz": -60,
     "elapsed": 740,
     "user": {
      "displayName": "Daniel Paysan",
      "photoUrl": "https://lh4.googleusercontent.com/-HjRiH1Pwbu0/AAAAAAAAAAI/AAAAAAAAAA8/hD4qoVYmxLY/s64/photo.jpg",
      "userId": "00174475314057917185"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    }
   },
   "cell_type": "code",
   "source": [
    "submission.iloc[:,0]= Lasso_coefs\n",
    "submission\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "wD_P3gKvc9NG",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Export data\n",
    "\n",
    "We finally use the Google Colab API to download our submission data frame in from of an csv, that we can submit to the submission platform."
   ]
  },
  {
   "metadata": {
    "id": "WNhRwnu7djcg",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "\n",
    "ts = str(datetime.datetime.utcnow())\n",
    "ts = ts.replace(' ', '_')\n",
    "fname = 'Lasso_full_alpha08_cv10_9980_std074'+ts+'.csv'\n",
    "\n",
    "with open(fname, 'w') as f:\n",
    "  submission.to_csv(f, float_format='%.64f', index=False, header=False)\n",
    "\n",
    "files.download(fname)"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}